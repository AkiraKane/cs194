{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: K-Means with SKLearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by loading some image data from the MNIST8M dataset. Since we have more resources now, we'll load 100k images instead of the 2-4k we've been working with in other labs. First some important imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py        # for binary IO\n",
    "import time\n",
    "import timeit\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then lets load a block of images. While we're doing that, we'll time the process (Note: Python has some other timing routines, but they often dont measure something other than wall clock time). Using time() gives us a direct measure of running time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "train = np.loadtxt(\"/data/MNIST8M/parts/alls00.fmat.txt\")\n",
    "dt1 = time.time() - t\n",
    "dt1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is a long time. Once we start dealing with large datasets, file formats become important. Lets compare with the time it takes to load the same data in binary format. We'll use HDF5, which is a standard binary file format for scientific data. Its accessible from Python (h5py package) and BIDMach and Matlab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "f = h5py.File(\"/data/MNIST8M/parts/alls00.mat\")\n",
    "train = f['mat'][:]\n",
    "dt2 = time.time() - t\n",
    "dt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. On top of that the binary file (which is automatically compressed) is 30 MB vs 300 MB for the text version of the file. We could have compressed the text file as well, but that would make reading it even slower.\n",
    "\n",
    "With larger datasets, you should use binary data representations whenever possible. Even if the data is text, you can represent it with integer word ids and a dictionary. The dictionary is typically a fraction of the size of original text, and processing integer data is orders of magnitude faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets train a kMeans model. Check the help page for this algorithm <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\">here</a> for explanation of what these options mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "dim = 100\n",
    "kmodel = KMeans(n_clusters=dim, init='random', n_init=1, max_iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets time model calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "kmodel.fit(train)\n",
    "dt = time.time() - t\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets load another chunk of the data for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = h5py.File(\"/data/MNIST8M/parts/alls01.mat\")\n",
    "test = f['mat'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the score of the clustering, we call the score function. That returns the total sum of squares of distance from test points to their cluster centroids. This number depends on the number of test points. To derive a more meaningful number, we divide by the number of test points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = kmodel.score(test)/test.shape[0]; \n",
    "print \"Time=\", dt, \" score=\", sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does cluster quality and running time vary with number of dimesions? Lets try..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dim = 300\n",
    "kmodel300 = KMeans(n_clusters=dim, init='random', n_init=1, max_iter=10)\n",
    "t = time.time()\n",
    "kmodel300.fit(train)\n",
    "dt = time.time() - t\n",
    "sc = kmodel300.score(test)/test.shape[0]; \n",
    "print \"Time=\", dt, \" score=\", sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell takes about 4 minutes.\n",
    "\n",
    "The score improved, but the time went up 10x. That's not good. The complexity seems to be growing quadraticly with the dimension. It should be linear. This is probably related to Scikit's automatic distance precomputation. Lets try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dim = 1000\n",
    "kmodel = KMeans(n_clusters=dim, init='random', n_init=1, max_iter=10)\n",
    "t = time.time()\n",
    "kmodel.fit(train)\n",
    "dt = time.time() - t\n",
    "sc = kmodel.score(test)/test.shape[0]; \n",
    "print \"Time=\", dt, \" score=\", sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> WARNING: Slow cell, you don't need to wait.\n",
    "\n",
    "Which should eventually give you something like: Time= 807.521463871  score= -1623958.78602\n",
    "\n",
    "This is good, and is back on track for linear complexity growth with dim. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switch Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch to the bidmach notebook now. You dont have to shut this one down. You can start another terminal to your instance and do <pre>bidmach notebook</pre>. But if you leave this one running make sure you check the socket number that bidmach notebook starts on. It will be something other than 8888. Make sure you point another browser window at <pre>http://localhost:socketnum</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume from BIDMach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load the model we just saved from BIDMach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = h5py.File(\"/data/MNIST8M/model.mat\")\n",
    "modelmat = f['model'][:]\n",
    "modelmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmodel300.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmodelmat = kmodel300.cluster_centers_\n",
    "kmodel300.score(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmodel.cluster_centers_ = np.transpose(modelmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmodel.score(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This difference is not significant. If you run KMeans again, you'll find it varies its score due to different random initializations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to BIDMach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save and shutdown this notebook now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
